{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "from tensorflow import test\n",
    "test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage, misc\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Dropout, GaussianNoise\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, Deconv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Conv3D, UpSampling3D, MaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K_backend\n",
    "from keras import objectives\n",
    "\n",
    "import models_basic\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from autoencoder import VAE_MNIST_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10, mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def redim(ary, ndim=4):\n",
    "    try: \n",
    "        w, x, y, z = ary.shape\n",
    "    except ValueError:\n",
    "        w, x, y = ary.shape\n",
    "        z = 1\n",
    "    if ndim==4:\n",
    "        return ary.reshape((w, x, y, z))\n",
    "    if ndim==3:\n",
    "        return ary.reshape((w, x, y))\n",
    "    if ndim==2:\n",
    "        return ary.reshape((w, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1) (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'mnist'\n",
    "if dataset == 'mnist':\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), 'edge')\n",
    "    x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), 'edge')\n",
    "    \n",
    "if x_train.ndim == 3:\n",
    "    s = x_train.shape\n",
    "    x_train = x_train.reshape((len(x_train), s[1], s[2], 1))\n",
    "    x_test = x_test.reshape((len(x_test), s[1], s[2], 1))\n",
    "original_img_size = x_train[0].shape\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train_oh = np.asarray(np_utils.to_categorical(y_train), 'float32')\n",
    "y_test_oh = np.asarray(np_utils.to_categorical(y_test), 'float32')\n",
    "\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(models_basic.SaveableModel):\n",
    "    \"\"\"\n",
    "    Base class for all-purpose autoencoder. VAE, CNN-AE, etc will be built off of this.\n",
    "\n",
    "    Input -> Encoder -> Z Latent Vector -> Decoder -> Output\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 latent_dim=2,  # Size of the encoded vector\n",
    "                 batch_size=100, # size of minibatch\n",
    "                 compile_decoder=False # create the decoder. Not necessary for every use case\n",
    "                 ):\n",
    "        self.model = None\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.compile_decoder = compile_decoder\n",
    "        assert K_backend.image_dim_ordering() == 'tf', 'Cannot support Theano ordering! Use TF ordering! #tensorflowmasterrace'\n",
    "\n",
    "        # input image dimensions\n",
    "        self.input_shape = input_shape\n",
    "        # self.data_shape = input_shape[1:] # Shape of a single sample\n",
    "        if len(input_shape) == 4:\n",
    "            self.img_rows, self.img_cols, self.img_stacks, self.img_chns = input_shape\n",
    "        elif len(input_shape) == 3:\n",
    "            self.img_rows, self.img_cols, self.img_chns = input_shape\n",
    "        elif len(input_shape) == 2:\n",
    "            self.img_rows, self.img_cols = input_shape\n",
    "            self.img_chns = 1\n",
    "        elif len(input_shape) == 1:\n",
    "            self.img_rows = input_shape[0]  # todo: test this\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input shape: {}\".format(input_shape))\n",
    "\n",
    "    def rollup_decoder(self, z, z_input, layers_list):\n",
    "        \"\"\"\n",
    "        Takes a list of Keras layers and returns the decoder back-half and the standalone decoder model\n",
    "        :param z: Layer corresponding to the latent space vector\n",
    "        :param z_input: Layer corresponding to the decoder input\n",
    "        :param layers_list: List of layers to roll up\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ae = AE_Dec()\n",
    "        dc = AE_Dec()\n",
    "        last_ae = z\n",
    "        last_dc = z_input\n",
    "        for i, layer in enumerate(layers_list):\n",
    "            #             if i ==0:\n",
    "            last_ae = layer(last_ae)\n",
    "            if self.compile_decoder:\n",
    "                last_dc = layer(last_dc)\n",
    "        return last_ae, last_dc\n",
    "\n",
    "\n",
    "class AE_Dec(object):\n",
    "    \"\"\"\n",
    "    Dummy object for reasons I can't remember. This may be deprecated.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class VAE(Autoencoder):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape=(28, 28, 1),\n",
    "                 latent_dim=2,  # Size of the encoded vector\n",
    "                 batch_size=100,  # size of minibatch\n",
    "                 epsilon_std=1.0, # This is the stddev for our normal-dist sampling of the latent vector\n",
    "                 compile_decoder=False\n",
    "                 ):\n",
    "        super().__init__(input_shape=input_shape, latent_dim=latent_dim, batch_size=batch_size,\n",
    "                         compile_decoder=compile_decoder)\n",
    "        # Necessary to instantiate this as instance variables such that they can be passed to the loss function (internally), since loss functions are\n",
    "        # all of the form lossfn(y_true, y_pred)\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.z_mean = Dense(latent_dim)\n",
    "        self.z_log_var = Dense(latent_dim)\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self, args):\n",
    "        \"\"\"\n",
    "        This is what makes the variational technique happen.\n",
    "        :param args:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Forging our latent vector from the reparameterized mean and std requires some sampling trickery\n",
    "        # that admittedly I do not understand in the slightest at this point in time\n",
    "        z_mean, z_log_var = args\n",
    "        batch_size = self.batch_size\n",
    "        epsilon = K_backend.random_normal(shape=(batch_size, self.latent_dim),\n",
    "                                          mean=0., stddev=self.epsilon_std)\n",
    "        # We return z_mean + epsilon*sigma^2. Not sure why we use log var\n",
    "        # Basically, create a random variable vector from the distribution\n",
    "        # We are learning a distribution (mu, var) which represents the input\n",
    "        return z_mean + K_backend.exp(z_log_var) * epsilon\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        \"\"\"\n",
    "        Custom loss function for VAE. Uses Kullback-Leibler divergence.\n",
    "\n",
    "        Notes from fchollet: binary_crossentropy expects a shape (batch_size, dim) for x and x_decoded_mean,\n",
    "        so we MUST flatten these!\n",
    "        :param x:\n",
    "        :param x_decoded_mean:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        x = K_backend.flatten(x)\n",
    "        x_decoded_mean = K_backend.flatten(x_decoded_mean)\n",
    "        shape_coef = np.product(self.input_shape)\n",
    "        xent_loss = shape_coef * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K_backend.mean(\n",
    "            1 + self.z_log_var - K_backend.square(self.z_mean) - K_backend.exp(self.z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "\n",
    "class DiscVAE(VAE):\n",
    "    \"\"\" Covolutional Discriminative VAE\n",
    "     Discriminative Regularization for Generative Models\n",
    "     \"\"\"\n",
    "    coef_xent = 1.\n",
    "    coef_kl = 1.\n",
    "    coef_disc = 0.1\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape=(64, 64, 3),\n",
    "                 latent_dim=256,  # Size of the encoded vector\n",
    "                 n_classes=10,  # number of classes in dataset\n",
    "                 batch_size=100,  # size of minibatch\n",
    "                 n_stacks=3,  # Number of convolayers to stack, this boosts performance of the network dramatically\n",
    "                 intermediate_dim=256,  # Size of the dense layer after convs\n",
    "                 n_filters=64,  # Number of filters in the first layer\n",
    "                 px_conv=3,  # Default convolution window size\n",
    "                 dropout_p=0.1,  # Default dropout rate\n",
    "                 epsilon_std=1.0,  # This is the stddev for our normal-dist sampling of the latent vector\n",
    "                 compile_decoder=True,\n",
    "                 ):\n",
    "\n",
    "        # This is my original crossfire network, and it works. As such, it has apprentice marks all over\n",
    "        # Reconstructing as-is before tinkering\n",
    "        # Based heavily on https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder_deconv.py\n",
    "        # and https://groups.google.com/forum/#!msg/keras-users/iBp3Ngxll3k/_GbY4nqNCQAJ\n",
    "\n",
    "        super().__init__(input_shape=input_shape, latent_dim=latent_dim, batch_size=batch_size, epsilon_std=epsilon_std,\n",
    "                         compile_decoder=compile_decoder)\n",
    "        self.new_model(input_shape=input_shape, latent_dim=latent_dim, n_stacks=n_stacks)\n",
    "        \n",
    "    def rollup_disc(self, z, z_input, layers_list, disc_list):\n",
    "        \"\"\"\n",
    "        Takes a list of Keras layers and returns the decoder back-half and the standalone decoder model\n",
    "        :param z: Layer corresponding to the latent space vector\n",
    "        :param z_input: Layer corresponding to the decoder input\n",
    "        :param layers_list: List of layers to roll up\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        last_ae = z\n",
    "        last_disc = z\n",
    "        last_dc = z_input\n",
    "        for i, layer in enumerate(layers_list):\n",
    "            #             if i ==0:\n",
    "            last_ae = layer(last_ae)\n",
    "            last_disc = layer(last_disc)\n",
    "            if self.compile_decoder:\n",
    "                last_dc = layer(last_dc)\n",
    "        for layer in disc_list:\n",
    "            last_disc = layer(last_disc)\n",
    "        return last_ae, last_dc, last_disc\n",
    "\n",
    "        \n",
    "    def discvae_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :param y: category\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        x = K_backend.flatten(self.x_in)\n",
    "        x_decoded_mean = K_backend.flatten(self.x_prime)\n",
    "        shape_coef = np.product(self.input_shape)\n",
    "        xent_loss = shape_coef * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        disc_loss = objectives.categorical_crossentropy(y_true, y_pred)\n",
    "        kl_loss = - 0.5 * K_backend.mean(\n",
    "            1 + self.z_log_var - K_backend.square(self.z_mean) - K_backend.exp(self.z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss + disc_loss\n",
    "\n",
    "\n",
    "    def new_model(self,\n",
    "                  input_shape=(64,64,3),\n",
    "                  latent_dim=512,\n",
    "                  kern=3,\n",
    "                  n_classes=10,\n",
    "                  n_filtersX=32,\n",
    "                  n_stacks=4,\n",
    "                  dropout_p=0.2,\n",
    "                  intermediate_dim=512):\n",
    "        # Convolutional frontend filters as per typical convonets\n",
    "        print(self.input_shape)\n",
    "\n",
    "        core_width = input_shape[0] // 2**n_stacks # this will probably break horribly for shapes not power of 2\n",
    "        n_filtersZ = n_filtersX * 2**(n_stacks-1)\n",
    "\n",
    "        x_in = Input(self.input_shape, name='main_input')\n",
    "        self.x_in = x_in\n",
    "        stack = x_in # bit of a hack so we can use a for loop here\n",
    "        \n",
    "        enc_list = [BatchNormalization()]\n",
    "        disc_list = [BatchNormalization()]\n",
    "\n",
    "        # -> CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout -> CONV/FC ->\n",
    "        for i in range(n_stacks):\n",
    "            enc_list.append(Conv2D(n_filtersX * 2 ** i, (kern, kern), padding='same', activation='relu', name='conv_{}a'.format(i)))\n",
    "            enc_list.append(BatchNormalization())\n",
    "            enc_list.append(Activation('relu'))\n",
    "            enc_list.append(Dropout(dropout_p))\n",
    "            enc_list.append(Conv2D(n_filtersX * 2 ** i, (kern, kern), padding='same', activation='relu', name='conv_{}b'.format(i)))\n",
    "            enc_list.append(BatchNormalization())\n",
    "            enc_list.append(Activation('relu'))\n",
    "#             enc_list.append(Dropout(dropout_p)) # dropout of 0.2 here causes network to NaN-out. Weird. \n",
    "            enc_list.append(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "            disc_list.append(Conv2D(n_filtersX * 2 ** i, (kern, kern), padding='same', activation='relu', name='conv_D{}a'.format(i)))\n",
    "            disc_list.append(BatchNormalization())\n",
    "            disc_list.append(Activation('relu'))\n",
    "            disc_list.append(Dropout(dropout_p))\n",
    "            disc_list.append(Conv2D(n_filtersX * 2 ** i, (kern, kern), padding='same', activation='relu', name='conv_D{}b'.format(i)))\n",
    "            disc_list.append(BatchNormalization())\n",
    "            disc_list.append(Activation('relu'))\n",
    "#             disc_list.append(Dropout(dropout_p)) # dropout of 0.2 here causes network to NaN-out. Weird. \n",
    "            disc_list.append(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "        for layer in enc_list:\n",
    "            stack = layer(stack) # ROLL OUT! \n",
    "\n",
    "        # Densely connected layer after the filters\n",
    "        flat = Flatten()(stack)\n",
    "        hidden_1 = Dense(intermediate_dim, activation='relu', name='intermezzo')(flat)\n",
    "\n",
    "        # This is the Variational Autoencoder reparameterization trick\n",
    "        z_mean = Dense(latent_dim)(hidden_1)\n",
    "        z_log_var = Dense(latent_dim)(hidden_1)\n",
    "\n",
    "        # Make these instance vars so X-Ent can use them. Probably a better way out there\n",
    "        self.z_mean = z_mean\n",
    "        self.z_log_var = z_log_var\n",
    "\n",
    "#         # Part 2 of the reparam trick is sample from the mean-vec and std-vec (log_var). To do this, we utilize a\n",
    "#         # custom layer via Lambda class to combine the mean and log_var outputs and a custom sampling function\n",
    "#         # 'z' is our latent vector\n",
    "        z = Lambda(self.sampling, output_shape=(latent_dim,), name='latent_z')([z_mean, z_log_var])\n",
    "#         print(z.shape)\n",
    "\n",
    "#         # This marks the end of the encoding portion of the VAE\n",
    "\n",
    "#         # On to Decoder. we instantiate these layers separately so as to reuse them later\n",
    "#         # e.g. for feeding in latent-space vectors, or (presumably) inspecting output\n",
    "\n",
    "        output_shape = (None, core_width, core_width, n_filtersZ)\n",
    "\n",
    "        decoder_hidden = Dense(intermediate_dim, activation='relu')\n",
    "        decoder_upsample = Dense(n_filtersZ * core_width**2, activation='relu')\n",
    "\n",
    "\n",
    "        decoder_reshape = Reshape(output_shape[1:])\n",
    "\n",
    "        dec_list = [decoder_hidden, decoder_upsample, decoder_reshape]\n",
    "\n",
    "        for i in range(n_stacks-1):\n",
    "            dec_list.append(UpSampling2D((2,2)))\n",
    "            dec_list.append(Deconv2D(n_filtersX * 2 ** (n_stacks-i-1), (kern, kern), padding='same', activation='relu', name='deconv_{}a'.format(i)))\n",
    "            dec_list.append(BatchNormalization())\n",
    "            dec_list.append(Activation('relu'))\n",
    "#             dec_list.append(Dropout(dropout_p))\n",
    "            dec_list.append(Deconv2D(n_filtersX * 2 ** (n_stacks-i-1), (kern, kern), padding='same', activation='relu', name='deconv_{}b'.format(i)))\n",
    "            dec_list.append(BatchNormalization())\n",
    "            dec_list.append(Activation('relu'))\n",
    "#             dec_list.append(Dropout(dropout_p))\n",
    "            \n",
    "        dec_list.append(UpSampling2D((2,2)))\n",
    "        dec_list.append(Conv2D(self.input_shape[2], (kern, kern), padding='same', activation='sigmoid', name='deconv_fin')) # trick to drop down to N channels from filters\n",
    "\n",
    "        decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "        # todo: better naming convention\n",
    "#         ae, dc = self.rollup_decoder(z, decoder_input, dec_list)\n",
    "        ae, dc, disc = self.rollup_disc(z, decoder_input, dec_list, disc_list)\n",
    "    \n",
    "        disc = Flatten()(disc)\n",
    "        disc = Dense(n_classes, activation='sigmoid')(disc) # classer\n",
    "\n",
    "        self.x_prime = ae\n",
    "\n",
    "#         # Now we create the actual models. We also compile them automatically, this could be isolated later\n",
    "#         # Primary model - VAE\n",
    "        self.model_ae = Model(x_in, ae)\n",
    "        self.model_ae.compile(optimizer='rmsprop', loss=self.vae_loss)\n",
    "        \n",
    "\n",
    "            \n",
    "        print(type(ae), type(disc))\n",
    "        print(disc)\n",
    "        self.model = Model(x_in, disc)\n",
    "        self.model.compile(optimizer='rmsprop', loss=self.discvae_loss) # loss=self.discvae_loss\n",
    "        \n",
    "\n",
    "\n",
    "        # build a model to project inputs on the latent space\n",
    "#         self.encoder = Model(x_in, self.z_mean)\n",
    "#         self.foo = Model(x_in, decoder_reshape)\n",
    "        if 0:# self.compile_decoder:\n",
    "            # reconstruct the digit pictures from latent space\n",
    "            self.decoder = Model(decoder_input, dc)\n",
    "\n",
    "    def fit_crossmodel(self, x_dict, y_dict, batch_size=None, nb_epoch=10, verbose=1, callbacks=[],\n",
    "                       validation_split=0.,\n",
    "                       validation_data=None, shuffle=True, class_weight=None, sample_weight=None):\n",
    "        pass\n",
    "        #     callbacks_history = self.crossmodel.fit(x_dict, y_dict, batch_size, nb_epoch, verbose, callbacks,\n",
    "        #                                             validation_split,\n",
    "        #                                             validation_data, shuffle, class_weight, sample_weight)\n",
    "        #     return callbacks_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"dense_7/Sigmoid:0\", shape=(?, 10), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 32, 32, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 32, 32, 1)     4                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_0a (Conv2D)                 (None, 32, 32, 32)    320                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 32, 32, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_0b (Conv2D)                 (None, 32, 32, 32)    9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 32, 32, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 16, 16, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1a (Conv2D)                 (None, 16, 16, 64)    18496                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1b (Conv2D)                 (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 8, 8, 64)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_2a (Conv2D)                 (None, 8, 8, 128)     73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_2b (Conv2D)                 (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 4, 4, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_3a (Conv2D)                 (None, 4, 4, 256)     295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_3b (Conv2D)                 (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 2, 2, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "intermezzo (Dense)               (None, 512)           524800                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           131328                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 256)           131328                                       \n",
      "____________________________________________________________________________________________________\n",
      "latent_z (Lambda)                (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1024)          525312                                       \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 2, 2, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_0a (Conv2DTranspose)      (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_0b (Conv2DTranspose)      (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 8, 8, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_1a (Conv2DTranspose)      (None, 8, 8, 128)     295040                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_1b (Conv2DTranspose)      (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 16, 16, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_2a (Conv2DTranspose)      (None, 16, 16, 64)    73792                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_2b (Conv2DTranspose)      (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 32, 32, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconv_fin (Conv2D)              (None, 32, 32, 1)     577                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 32, 32, 1)     4                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D0a (Conv2D)                (None, 32, 32, 32)    320                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 32, 32, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D0b (Conv2D)                (None, 32, 32, 32)    9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 32, 32, 32)    128                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 32, 32, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 16, 16, 32)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D1a (Conv2D)                (None, 16, 16, 64)    18496                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D1b (Conv2D)                (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 8, 8, 64)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D2a (Conv2D)                (None, 8, 8, 128)     73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D2b (Conv2D)                (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 4, 4, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D3a (Conv2D)                (None, 4, 4, 256)     295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_D3b (Conv2D)                (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 2, 2, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1024)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            10250                                        \n",
      "====================================================================================================\n",
      "Total params: 5,543,315.0\n",
      "Trainable params: 5,537,679.0\n",
      "Non-trainable params: 5,636.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import autoencoder\n",
    "from imp import reload\n",
    "reload(autoencoder)\n",
    "\n",
    "# aeclass = autoencoder.VAE_MNIST_0(batch_size=100, n_stacks=0, compile_decoder=False)\n",
    "aeclass = DiscVAE(input_shape=x_train[0].shape, n_stacks=4, n_classes=y_train_oh.shape[1])\n",
    "print(aeclass.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/ve/keras/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6a035c59fc4b9d9efd6040c56be45c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668ae25b7f8a433a89b11a7c73e211bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ac177aa75916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maeclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mike/ve/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aeclass.model.fit(x_train, y_train_oh, batch_size=100, nb_epoch=1, verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "aeclass.model_ae.fit(x_train, x_train, batch_size=100, nb_epoch=2, verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pp = aeclass.model_ae.predict(redim(x_test), batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n = 112\n",
    "if x_test.shape[-1] == 1:\n",
    "    s = pp.shape\n",
    "    pp = pp.reshape((s[0], s[1], s[2]))\n",
    "    x_test = x_test.reshape((len(x_test), s[1], s[2]))\n",
    "    \n",
    "print(np.amax(x_test[n]), np.amax(pp[n]))\n",
    "print(np.amin(x_test[n]), np.amin(pp[n]))\n",
    "plt.imshow(x_test[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redim(pp[n], 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(redim(pp[n], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder\n",
    "with Keras and deconvolution layers.\n",
    "\n",
    "Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, Deconvolution2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "batch_size = 100\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    original_img_size = (img_chns, img_rows, img_cols)\n",
    "else:\n",
    "    original_img_size = (img_rows, img_cols, img_chns)\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 0.01\n",
    "nb_epoch = 2\n",
    "\n",
    "x = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)\n",
    "conv_2 = Convolution2D(nb_filters, 2, 2,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(2, 2))(conv_1)\n",
    "conv_3 = Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(1, 1))(conv_2)\n",
    "conv_4 = Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(1, 1))(conv_3)\n",
    "flat = Flatten()(conv_4)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    output_shape = (batch_size, nb_filters, 14, 14)\n",
    "else:\n",
    "    output_shape = (batch_size, 14, 14, nb_filters)\n",
    "\n",
    "decoder_reshape = Reshape(output_shape[1:])\n",
    "decoder_deconv_1 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                                   output_shape,\n",
    "                                   border_mode='same',\n",
    "                                   subsample=(1, 1),\n",
    "                                   activation='relu')\n",
    "decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                                   output_shape,\n",
    "                                   border_mode='same',\n",
    "                                   subsample=(1, 1),\n",
    "                                   activation='relu')\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    output_shape = (batch_size, nb_filters, 29, 29)\n",
    "else:\n",
    "    output_shape = (batch_size, 29, 29, nb_filters)\n",
    "decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,\n",
    "                                          output_shape,\n",
    "                                          border_mode='valid',\n",
    "                                          subsample=(2, 2),\n",
    "                                          activation='relu')\n",
    "decoder_mean_squash = Convolution2D(img_chns, 2, 2,\n",
    "                                    border_mode='valid',\n",
    "                                    activation='sigmoid')\n",
    "\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded = decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # NOTE: binary_crossentropy expects a batch_size by dim\n",
    "    # for x and x_decoded_mean, so we MUST flatten these!\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[:, :28, :28]\n",
    "x_test = x_test[:, :28, :28]\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n",
    "\n",
    "print('x_train.shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x1, x1,\n",
    "        shuffle=True,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test), \n",
    "       verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_hid_decoded = decoder_hid(decoder_input)\n",
    "_up_decoded = decoder_upsample(_hid_decoded)\n",
    "_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n",
    "_deconv_2_decoded = decoder_deconv_2(_deconv_1_decoded)\n",
    "_x_decoded_relu = decoder_deconv_3_upsamp(_deconv_2_decoded)\n",
    "_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n",
    "generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n, x_train.shape[3]))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = generator.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape((digit_size, digit_size, -1))\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
